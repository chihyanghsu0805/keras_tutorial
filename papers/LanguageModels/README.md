# This folder contains Language Model papers.

- RoBERTa: ARobustly Optimized BERT
  - https://arxiv.org/abs/1907.11692

- Large Batch Optimization for Deep Learning: Training BERT in 76 minutes
  - https://arxiv.org/abs/1904.00962

- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
  - https://arxiv.org/abs/1810.04805
