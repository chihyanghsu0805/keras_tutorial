This folder contains papers in deep learning.
Related works are grouped in individual folders.

ECCV:
-   2020
    -   Big Transfer (BiT): General Visual Representation Learning
        -   https://arxiv.org/abs/1912.11370
-   2016
    -   Deep Networks with Stochastic Depth
        -   https://arxiv.org/abs/1603.09382

ICLR:
- 2022:
    -   ViDT: An Efficient and Effective Fully Transformer-based Object Detector
        -   https://arxiv.org/abs/2110.03921
    -   Learning Strides in Convolutional Neural Networks
        -   https://arxiv.org/abs/2202.01653
        -   https://github.com/google-research/diffstride
    - ViTGAN: Training GANs with Vision Transformers
        -   https://arxiv.org/abs/2107.04589        -   
    - PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions
        -   https://arxiv.org/abs/2204.12511
    - Natural Language Descriptions of Deep Visual Features
        - https://arxiv.org/abs/2201.11114
    -   Pix2Seq: A Language Modeling Framework for Object Detection
        -   https://arxiv.org/pdf/2109.10852.pdf

-   2021:
    -   Deformable DETR: Deformable Transformers for End-to-End Object Detection
        -   https://arxiv.org/pdf/2010.04159.pdf

- 2018:
    -   Spectral Normalization for Generative Adversarial Networks
        -   https://arxiv.org/abs/1802.05957
    - Graph Attention Networks
        - https://arxiv.org/abs/1710.10903
        - https://github.com/PetarV-/GAT
        
CogSci:
- 2021:
    - Are Convolutional Neural Networks or Transformers more like human vision?
        - https://arxiv.org/abs/2105.07197

ICCV:
- 2021:    
    - Explaining in Style: Training a GAN to explain a classifier in StyleSpace
        - https://arxiv.org/pdf/2104.13369.pdf
        - https://explaining-in-style.github.io/

    -   Deformable Convolutional Networks
        -   https://github.com/msracver/Deformable-ConvNets
        -   https://arxiv.org/abs/1703.06211
        -   
NIPS:
- 2021:
    - Do Vision Transformers See Like Convolutional Neural Networks?
        - https://arxiv.org/abs/2108.08810

    - MLP-Mixer: An all-MLP Architecture for Vision
        - https://arxiv.org/pdf/2105.01601.pdf
        - https://github.com/google-research/vision_transformer

    2020:
    - Debugging Tests for Model Explanations
        - https://arxiv.org/abs/2011.05429

CVPR:
-   2022:
    -   LiT: Zero-Shot Transfer with Locked-image text Tuning
        -   https://arxiv.org/abs/2111.07991

- 2020:
    - Self-training with Noisy Student improves ImageNet classification
        - https://arxiv.org/abs/1911.04252
        - https://github.com/google-research/noisystudent

    - Learning Texture Transformer Network for Image Super-Resolution
        - https://arxiv.org/abs/2006.04139
        - https://github.com/researchmm/TTSR

    - Bringing Old Photos Back to Life
        - https://arxiv.org/abs/2004.09484
        - https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life

    -   RandAugment: Practical automated data augmentation with a reduced search space
        -   https://arxiv.org/abs/1909.13719
        -   https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet

- 2016:
    - Learning Deep Features for Discriminative Localization
        - https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf
        - https://github.com/zhoubolei/CAM

Google AI Blog:
- Accurate Alpha Matting for Portrait Mode Selfies on Pixel 6
    - https://ai.googleblog.com/2022/01/accurate-alpha-matting-for-portrait.html
